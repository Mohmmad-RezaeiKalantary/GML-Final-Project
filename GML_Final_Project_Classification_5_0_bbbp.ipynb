{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GML Final Project Classification on bbbp Dataset"
      ],
      "metadata": {
        "id": "UrK6SXbwqVB3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBABnTZKncKU",
        "outputId": "6f950510-e95f-44f6-92af-cfd618fbe2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl -f https://data.dgl.ai/wheels/repo.html\n",
        "\n",
        "!pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html"
      ],
      "metadata": {
        "id": "svYZdSBIDaAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b930a94d-bf8f-4398-bb8a-ec736d412cdd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl\n",
            "  Downloading dgl-1.1.1-cp310-cp310-manylinux1_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.1\n",
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Collecting dglgo\n",
            "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.7.0)\n",
            "Collecting isort>=5.10.1 (from dglgo)\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopep8>=1.6.0 (from dglgo)\n",
            "  Downloading autopep8-2.0.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/numpydoc/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting numpydoc>=1.1.0 (from dglgo)\n",
            "  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.9)\n",
            "Collecting ruamel.yaml>=0.17.20 (from dglgo)\n",
            "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0)\n",
            "Collecting ogb>=1.3.3 (from dglgo)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit-pypi (from dglgo)\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
            "Collecting pycodestyle>=2.10.0 (from autopep8>=1.6.0->dglgo)\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Collecting sphinx>=4.2 (from numpydoc>=1.1.0->dglgo)\n",
            "  Downloading sphinx-7.0.1-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.65.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.26.16)\n",
            "Collecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.6.3)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.20->dglgo)\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Collecting docutils<0.21,>=0.18.1 (from sphinx>=4.2->numpydoc>=1.1.0->dglgo)\n",
            "  Downloading docutils-0.20.1-py3-none-any.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=9034184ee7bbd7796f7300f664811ac47d14a42a69884d4359ab401c03a28399\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, pycodestyle, isort, docutils, sphinx, ruamel.yaml, outdated, autopep8, numpydoc, ogb, dglgo\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 3.5.4\n",
            "    Uninstalling Sphinx-3.5.4:\n",
            "      Successfully uninstalled Sphinx-3.5.4\n",
            "Successfully installed autopep8-2.0.2 dglgo-0.0.2 docutils-0.20.1 isort-5.12.0 littleutils-0.2.2 numpydoc-1.5.0 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.10.0 rdkit-pypi-2022.9.5 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 sphinx-7.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D_YeNQqzASGT"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl.function as fn\n",
        "import torch.nn.functional as F\n",
        "import shutil\n",
        "from torch.utils.data import DataLoader\n",
        "import cloudpickle\n",
        "from dgl.nn import GraphConv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B52LUH9SASGU"
      },
      "source": [
        "#### Set Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4iff64pKASGU"
      },
      "outputs": [],
      "source": [
        "current_dir = \"/content/drive/MyDrive/GML Final Project/\"\n",
        "checkpoint_path = current_dir + \"save_models/model_checkpoints/\" + \"checkpoint\"\n",
        "os.makedirs(checkpoint_path, exist_ok=True)\n",
        "\n",
        "best_model_path = current_dir + \"save_models/best_model/\"\n",
        "\n",
        "folder_data_temp = current_dir +\"data_temp/\"\n",
        "shutil.rmtree(folder_data_temp, ignore_errors=True)\n",
        "\n",
        "path_save = current_dir + \"Hiv.zip\"\n",
        "shutil.unpack_archive(path_save, folder_data_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK4f61xsASGU"
      },
      "source": [
        "#### Custom PyTorch Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6jjoK6a_ASGV"
      },
      "outputs": [],
      "source": [
        "\"\"\" Classification Dataset \"\"\"\n",
        "class DGLDatasetClass(torch.utils.data.Dataset):\n",
        "    def __init__(self, address):\n",
        "      #initializes the dataset by loading the preprocessed graphs, labels, masks, and global features from the specified binary file using the dgl.load_graphs() function.\n",
        "            self.address=address+\".bin\"\n",
        "            self.list_graphs, train_labels_masks_globals = dgl.load_graphs(self.address)\n",
        "      #The number of graphs in the dataset is calculated and stored as num_graphs.\n",
        "            num_graphs =len(self.list_graphs)\n",
        "      #The labels, masks, and global features are extracted from the loaded data and reshaped into 2-dimensional tensors, where each row represents a graph.\n",
        "            self.labels = train_labels_masks_globals[\"labels\"].view(num_graphs,-1)\n",
        "            self.masks = train_labels_masks_globals[\"masks\"].view(num_graphs,-1)\n",
        "            self.globals = train_labels_masks_globals[\"globals\"].view(num_graphs,-1)\n",
        "      #The __len__() method overrides the base class method and returns the length of the dataset, which is the number of graphs.\n",
        "    def __len__(self):\n",
        "        return len(self.list_graphs)\n",
        "      #The __getitem__(self, idx) method overrides the base class method and returns the graph at the specified index (idx), along with its corresponding label, mask, and global features.\n",
        "    def __getitem__(self, idx):\n",
        "        return  self.list_graphs[idx], self.labels[idx], self.masks[idx], self.globals[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPsfcGUPASGV"
      },
      "source": [
        "#### Defining Train, Validation, and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W0KbV4qASGV",
        "outputId": "b14ddd6f-2ddd-4a4e-95b6-851a59e402ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32901 4112 4114\n"
          ]
        }
      ],
      "source": [
        "path_data_temp = folder_data_temp + \"scaffold\"+\"_\"+str(0)\n",
        "train_set = DGLDatasetClass(address=path_data_temp+\"_train\")\n",
        "val_set = DGLDatasetClass(address=path_data_temp+\"_val\")\n",
        "test_set = DGLDatasetClass(address=path_data_temp+\"_test\")\n",
        "\n",
        "print(len(train_set), len(val_set), len(test_set))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyX3bz0JASGW"
      },
      "source": [
        "#### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2YWfwaXPASGW"
      },
      "outputs": [],
      "source": [
        "def collate(batch):\n",
        "    # batch is a list of tuples (graphs, labels, masks, globals)\n",
        "    # Concatenate a sequence of graphs\n",
        "\n",
        "    ### This line extracts the graphs from each tuple in the batch and creates a list of individual graphs.\n",
        "    graphs = [e[0] for e in batch]\n",
        "    ### This line uses the dgl.batch() function to combine the individual graphs into a single graph batch g\n",
        "    g = dgl.batch(graphs)\n",
        "\n",
        "    # Concatenate a sequence of tensors (labels) along a new dimension\n",
        "\n",
        "    ### This line extracts the labels from each tuple in the batch and creates a list of individual label tensors.\n",
        "    labels = [e[1] for e in batch]\n",
        "    ### This line uses torch.stack() to concatenate the individual label tensors along a new dimension (dimension 0) and create a single tensor labels representing the labels for the entire batch.\n",
        "    labels = torch.stack(labels, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (masks) along a new dimension\n",
        "\n",
        "    ### This line extracts the masks from each tuple in the batch and creates a list of individual mask tensors.\n",
        "    masks = [e[2] for e in batch]\n",
        "    ### This line uses torch.stack() to concatenate the individual mask tensors along a new dimension (dimension 0) and create a single tensor masks representing the masks for the entire batch.\n",
        "    masks = torch.stack(masks, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (globals) along a new dimension\n",
        "\n",
        "    ### This line extracts the global features from each tuple in the batch and creates a list of individual global feature tensors.\n",
        "    globals = [e[3] for e in batch]\n",
        "    ### This line uses torch.stack() to concatenate the individual global feature tensors along a new dimension (dimension 0) and create a single tensor globals representing the global features for the entire batch.\n",
        "    globals = torch.stack(globals, 0)\n",
        "\n",
        "    return g, labels, masks, globals\n",
        "\n",
        "\n",
        "def loader(batch_size=64):\n",
        "    train_dataloader = DataLoader(train_set,\n",
        "                              batch_size=batch_size,\n",
        "                              collate_fn=collate,\n",
        "                              drop_last=False,\n",
        "                              shuffle=True,\n",
        "                              num_workers=1)\n",
        "\n",
        "    val_dataloader =  DataLoader(val_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sF12sk5xASGW"
      },
      "outputs": [],
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = loader(batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDCovh9SASGX"
      },
      "source": [
        "#### Defining A GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHGt8PHNASGX"
      },
      "source": [
        "##### Some Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cn-OqoOBASGa"
      },
      "outputs": [],
      "source": [
        "#Bace dataset has 1 task. Some other datasets may have some more number of tasks, e.g., tox21 has 12 tasks.\n",
        "num_tasks = 1\n",
        "\n",
        "# Size of global feature of each graph\n",
        "global_size = 200\n",
        "\n",
        "# Number of epochs to train the model\n",
        "num_epochs = 100\n",
        "\n",
        "# Number of steps to wait if the model performance on the validation set does not improve\n",
        "patience = 10\n",
        "\n",
        "#Configurations to instantiate the model\n",
        "config = {\"node_feature_size\":127, \"edge_feature_size\":12, \"hidden_size\":100}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QcssOpOTASGf"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv3 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv4 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "\n",
        "        h = mol_dgl_graph.ndata[\"v\"]\n",
        "        h = self.conv1(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J77vGpO0ASGf"
      },
      "source": [
        "#### Function to Compute Score of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fHh6ojitASGf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNqnTgo1ASGi"
      },
      "source": [
        "#### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S2P4zFBDASGj"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    #This tensor is used as a weight for positive examples in the binary cross-entropy loss.\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    #reduction='none': This specifies that the loss should not be reduced and returned element-wise.\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    #The mask tensor is used to mask out the loss for invalid labels.\n",
        "    loss = mask*criterion(output,label)\n",
        "    #The masked loss is summed and divided by the sum of the mask to compute the average loss.\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnNBJ3zOASGj"
      },
      "source": [
        "#### Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU3F2tsyASGk"
      },
      "source": [
        "##### Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gww5dkL-ASGk"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        # Zeros out the gradients of the model parameters using\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        # Computes the gradients of the loss with respect to the model parameters using\n",
        "        loss_train.backward()\n",
        "        # Updates the model parameters using\n",
        "        optimizer.step()\n",
        "        # Adds the loss for the current batch to\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E13DdiwNASGl"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpR2rrCHASGl"
      },
      "source": [
        "##### Function to compute test set score of the final saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xCHj4lduASGl"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzx--7g_ASGm"
      },
      "source": [
        "##### Train the model and evaluate its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w14ooP9mASGm",
        "outputId": "0e54d136-8d73-44b8-94f3-9b23d63ee2a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.229 | Valid Score: 0.557\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.557 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.155 | Valid Score: 0.661\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.661 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.149 | Valid Score: 0.727\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.727 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.145 | Valid Score: 0.742\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.742 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.143 | Valid Score: 0.745\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.745 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.143 | Valid Score: 0.747\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.747 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.141 | Valid Score: 0.750\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.750 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.140 | Valid Score: 0.754\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.754 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.140 | Valid Score: 0.754\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.754 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.139 | Valid Score: 0.756\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.756 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.140 | Valid Score: 0.758\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.758 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.139 | Valid Score: 0.761\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.761 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.138 | Valid Score: 0.764\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 14/100 | Training Loss: 0.137 | Valid Score: 0.763\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 15/100 | Training Loss: 0.137 | Valid Score: 0.761\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 16/100 | Training Loss: 0.137 | Valid Score: 0.763\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.137 | Valid Score: 0.769\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 18/100 | Training Loss: 0.136 | Valid Score: 0.768\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.136 | Valid Score: 0.771\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.771 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 20/100 | Training Loss: 0.135 | Valid Score: 0.768\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.771 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.135 | Valid Score: 0.771\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.771 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 22/100 | Training Loss: 0.134 | Valid Score: 0.770\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.771 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.136 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.133 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 0.133 | Valid Score: 0.777\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.777 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 26/100 | Training Loss: 0.133 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.777 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.132 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.780 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 0.131 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.780 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 29/100 | Training Loss: 0.131 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.780 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 30/100 | Training Loss: 0.131 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.780 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 0.131 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 32/100 | Training Loss: 0.130 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 33/100 | Training Loss: 0.129 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 34/100 | Training Loss: 0.129 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.129 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 36/100 | Training Loss: 0.128 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 37/100 | Training Loss: 0.128 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 0.128 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.127 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 40/100 | Training Loss: 0.127 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 41/100 | Training Loss: 0.127 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 42/100 | Training Loss: 0.127 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 43/100 | Training Loss: 0.126 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 44/100 | Training Loss: 0.126 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 45/100 | Training Loss: 0.126 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 0.127 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 47/100 | Training Loss: 0.125 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 48/100 | Training Loss: 0.125 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 0.126 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 0.124 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 51/100 | Training Loss: 0.124 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 0.124 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 53/100 | Training Loss: 0.123 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 54/100 | Training Loss: 0.123 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 55/100 | Training Loss: 0.124 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 56/100 | Training Loss: 0.123 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 57/100 | Training Loss: 0.122 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 0.122 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 59/100 | Training Loss: 0.122 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 60/100 | Training Loss: 0.122 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 0.122 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 62/100 | Training Loss: 0.121 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 63/100 | Training Loss: 0.121 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 64/100 | Training Loss: 0.121 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 65/100 | Training Loss: 0.121 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 66/100 | Training Loss: 0.121 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 67/100 | Training Loss: 0.120 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 0.120 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 0.120 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 70/100 | Training Loss: 0.119 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 71/100 | Training Loss: 0.120 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 72/100 | Training Loss: 0.119 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 0.120 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 74/100 | Training Loss: 0.119 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 75/100 | Training Loss: 0.118 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 76/100 | Training Loss: 0.118 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 77/100 | Training Loss: 0.118 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 78/100 | Training Loss: 0.118 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 79/100 | Training Loss: 0.117 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 80/100 | Training Loss: 0.118 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 81/100 | Training Loss: 0.117 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 82/100 | Training Loss: 0.118 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 0.117 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 84/100 | Training Loss: 0.117 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 85/100 | Training Loss: 0.116 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 86/100 | Training Loss: 0.116 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 87/100 | Training Loss: 0.116 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 0.116 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 89/100 | Training Loss: 0.116 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 90/100 | Training Loss: 0.115 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 91/100 | Training Loss: 0.116 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 92/100 | Training Loss: 0.115 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 93/100 | Training Loss: 0.115 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 94/100 | Training Loss: 0.115 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 95/100 | Training Loss: 0.114 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 96/100 | Training Loss: 0.114 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 97/100 | Training Loss: 0.114 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 98/100 | Training Loss: 0.114 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 99/100 | Training Loss: 0.114 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 100/100 | Training Loss: 0.114 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.818 \n",
            "\n",
            "Test Score: 0.760 \n",
            "\n",
            "Execution time: 1087.717 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN 2Layer"
      ],
      "metadata": {
        "id": "8hiKx-ix9kF1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rojzTwdT9vhH"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YdQs9Cdq9vhI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xIa2rB5T9vhI"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    #This tensor is used as a weight for positive examples in the binary cross-entropy loss.\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    #reduction='none': This specifies that the loss should not be reduced and returned element-wise.\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    #The mask tensor is used to mask out the loss for invalid labels.\n",
        "    loss = mask*criterion(output,label)\n",
        "    #The masked loss is summed and divided by the sum of the mask to compute the average loss.\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "k1sNhadU9vhI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        # Zeros out the gradients of the model parameters using\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        # Computes the gradients of the loss with respect to the model parameters using\n",
        "        loss_train.backward()\n",
        "        # Updates the model parameters using\n",
        "        optimizer.step()\n",
        "        # Adds the loss for the current batch to\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "g56YpLRM9vhI"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "q0uFhtT59vhJ"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd803d47-acf6-4d3d-df96-4e71e5abdf94",
        "id": "mV2wRPbK9vhJ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.463 | Valid Score: 0.498\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.498 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.168 | Valid Score: 0.508\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.508 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.164 | Valid Score: 0.520\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.520 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.162 | Valid Score: 0.534\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.534 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.160 | Valid Score: 0.554\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.554 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.158 | Valid Score: 0.577\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.577 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.158 | Valid Score: 0.606\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.606 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.154 | Valid Score: 0.635\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.635 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.152 | Valid Score: 0.654\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.654 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.151 | Valid Score: 0.673\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.673 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.150 | Valid Score: 0.685\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.685 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.148 | Valid Score: 0.695\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.695 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.147 | Valid Score: 0.702\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.702 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.147 | Valid Score: 0.708\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.708 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.146 | Valid Score: 0.711\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.711 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.146 | Valid Score: 0.711\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.711 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.145 | Valid Score: 0.715\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.715 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.145 | Valid Score: 0.717\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.717 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.146 | Valid Score: 0.718\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.718 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.144 | Valid Score: 0.719\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.719 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.144 | Valid Score: 0.721\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.721 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.144 | Valid Score: 0.722\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.722 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.144 | Valid Score: 0.722\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.722 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.144 | Valid Score: 0.723\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.723 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 0.143 | Valid Score: 0.725\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.725 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 0.143 | Valid Score: 0.727\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.727 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 27/100 | Training Loss: 0.143 | Valid Score: 0.726\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.727 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 28/100 | Training Loss: 0.143 | Valid Score: 0.726\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.727 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 0.143 | Valid Score: 0.729\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.729 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 0.142 | Valid Score: 0.731\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.731 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 0.142 | Valid Score: 0.732\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.732 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 0.142 | Valid Score: 0.732\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.732 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.142 | Valid Score: 0.734\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.734 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 0.142 | Valid Score: 0.734\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.734 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.142 | Valid Score: 0.735\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.735 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 36/100 | Training Loss: 0.142 | Valid Score: 0.735\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.735 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 0.142 | Valid Score: 0.736\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.736 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 0.142 | Valid Score: 0.737\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.737 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.141 | Valid Score: 0.738\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.738 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 0.141 | Valid Score: 0.739\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.739 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 0.141 | Valid Score: 0.739\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.739 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 42/100 | Training Loss: 0.141 | Valid Score: 0.739\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.739 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 0.141 | Valid Score: 0.740\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.740 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 0.141 | Valid Score: 0.742\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.742 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 45/100 | Training Loss: 0.141 | Valid Score: 0.742\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.742 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 46/100 | Training Loss: 0.141 | Valid Score: 0.742\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.742 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 47/100 | Training Loss: 0.141 | Valid Score: 0.742\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.742 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 0.140 | Valid Score: 0.744\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.744 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 49/100 | Training Loss: 0.140 | Valid Score: 0.743\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.744 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 0.140 | Valid Score: 0.745\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.745 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 0.140 | Valid Score: 0.747\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.747 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 0.140 | Valid Score: 0.747\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.747 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 0.140 | Valid Score: 0.749\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.749 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 54/100 | Training Loss: 0.141 | Valid Score: 0.746\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.749 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 55/100 | Training Loss: 0.140 | Valid Score: 0.748\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.749 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 56/100 | Training Loss: 0.141 | Valid Score: 0.748\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.749 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 57/100 | Training Loss: 0.140 | Valid Score: 0.750\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.750 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 0.139 | Valid Score: 0.751\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.751 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 0.139 | Valid Score: 0.751\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.751 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 60/100 | Training Loss: 0.140 | Valid Score: 0.750\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.751 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 61/100 | Training Loss: 0.139 | Valid Score: 0.750\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.751 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 0.139 | Valid Score: 0.752\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.752 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 63/100 | Training Loss: 0.139 | Valid Score: 0.751\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.752 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 0.139 | Valid Score: 0.752\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.752 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 0.139 | Valid Score: 0.753\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.753 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 66/100 | Training Loss: 0.139 | Valid Score: 0.754\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.754 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 0.141 | Valid Score: 0.754\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.754 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 0.138 | Valid Score: 0.755\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.755 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 0.138 | Valid Score: 0.755\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.755 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 70/100 | Training Loss: 0.139 | Valid Score: 0.755\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.755 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 0.138 | Valid Score: 0.757\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.757 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 72/100 | Training Loss: 0.138 | Valid Score: 0.755\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.757 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 73/100 | Training Loss: 0.138 | Valid Score: 0.756\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.757 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 74/100 | Training Loss: 0.138 | Valid Score: 0.756\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.757 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 75/100 | Training Loss: 0.138 | Valid Score: 0.756\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.757 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 76/100 | Training Loss: 0.138 | Valid Score: 0.756\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.757 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 77/100 | Training Loss: 0.139 | Valid Score: 0.756\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.757 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 0.138 | Valid Score: 0.758\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.758 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 79/100 | Training Loss: 0.138 | Valid Score: 0.757\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.758 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 80/100 | Training Loss: 0.137 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 81/100 | Training Loss: 0.137 | Valid Score: 0.758\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 82/100 | Training Loss: 0.139 | Valid Score: 0.759\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 83/100 | Training Loss: 0.137 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 84/100 | Training Loss: 0.137 | Valid Score: 0.758\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 85/100 | Training Loss: 0.137 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 86/100 | Training Loss: 0.137 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 0.137 | Valid Score: 0.761\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 0.761 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 0.138 | Valid Score: 0.763\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 0.763 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 89/100 | Training Loss: 0.139 | Valid Score: 0.761\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 0.763 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 90/100 | Training Loss: 0.137 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 0.763 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 91/100 | Training Loss: 0.137 | Valid Score: 0.764\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 92/100 | Training Loss: 0.137 | Valid Score: 0.762\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 93/100 | Training Loss: 0.137 | Valid Score: 0.762\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 94/100 | Training Loss: 0.138 | Valid Score: 0.762\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 95/100 | Training Loss: 0.136 | Valid Score: 0.763\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 96/100 | Training Loss: 0.136 | Valid Score: 0.764\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 97/100 | Training Loss: 0.136 | Valid Score: 0.764\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 98/100 | Training Loss: 0.138 | Valid Score: 0.764\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 99/100 | Training Loss: 0.136 | Valid Score: 0.763\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 100/100 | Training Loss: 0.136 | Valid Score: 0.763\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.764 \n",
            "\n",
            "Test Score: 0.699 \n",
            "\n",
            "Execution time: 914.096 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gCwdxuEd9mZu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GraphSage 3Layer"
      ],
      "metadata": {
        "id": "8SwGocCi9m-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.nn import SAGEConv"
      ],
      "metadata": {
        "id": "UEr4V9EkAMXm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-gCKQSrr9wLn"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size,aggregator_type='mean')\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.hidden_size,aggregator_type='mean')\n",
        "        self.conv3 = SAGEConv(self.hidden_size, self.num_tasks,aggregator_type='mean')\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "G_5wrah-9wLn"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Qsyihux49wLn"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    #This tensor is used as a weight for positive examples in the binary cross-entropy loss.\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    #reduction='none': This specifies that the loss should not be reduced and returned element-wise.\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    #The mask tensor is used to mask out the loss for invalid labels.\n",
        "    loss = mask*criterion(output,label)\n",
        "    #The masked loss is summed and divided by the sum of the mask to compute the average loss.\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_ydjPeOA9wLn"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        # Zeros out the gradients of the model parameters using\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        # Computes the gradients of the loss with respect to the model parameters using\n",
        "        loss_train.backward()\n",
        "        # Updates the model parameters using\n",
        "        optimizer.step()\n",
        "        # Adds the loss for the current batch to\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gPgcF8hf9wLn"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "z4a6ayNF9wLo"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59691165-3004-44a1-db58-0ce2c83d06fd",
        "id": "8ypvMm6b9wLo"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.156 | Valid Score: 0.709\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.709 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.142 | Valid Score: 0.753\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.753 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.139 | Valid Score: 0.769\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.137 | Valid Score: 0.778\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.137 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 6/100 | Training Loss: 0.134 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.133 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 8/100 | Training Loss: 0.132 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.131 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.795 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.131 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.130 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.128 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 13/100 | Training Loss: 0.128 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 14/100 | Training Loss: 0.127 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 15/100 | Training Loss: 0.126 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.126 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.125 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 18/100 | Training Loss: 0.124 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 19/100 | Training Loss: 0.124 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 20/100 | Training Loss: 0.123 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 21/100 | Training Loss: 0.123 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 22/100 | Training Loss: 0.122 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 23/100 | Training Loss: 0.123 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.121 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 25/100 | Training Loss: 0.121 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 26/100 | Training Loss: 0.121 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.120 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 0.119 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 29/100 | Training Loss: 0.119 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 30/100 | Training Loss: 0.118 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 0.118 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 32/100 | Training Loss: 0.118 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 33/100 | Training Loss: 0.118 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 0.117 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.118 | Valid Score: 0.819\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.819 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 36/100 | Training Loss: 0.116 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.819 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 37/100 | Training Loss: 0.116 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.819 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 38/100 | Training Loss: 0.115 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.819 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.115 | Valid Score: 0.819\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.819 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 40/100 | Training Loss: 0.115 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.819 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 0.115 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 42/100 | Training Loss: 0.114 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 43/100 | Training Loss: 0.114 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 44/100 | Training Loss: 0.114 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 45/100 | Training Loss: 0.114 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 46/100 | Training Loss: 0.113 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 0.113 | Valid Score: 0.826\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 48/100 | Training Loss: 0.113 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 49/100 | Training Loss: 0.112 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 50/100 | Training Loss: 0.112 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 51/100 | Training Loss: 0.112 | Valid Score: 0.825\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 52/100 | Training Loss: 0.111 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 53/100 | Training Loss: 0.111 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 54/100 | Training Loss: 0.111 | Valid Score: 0.825\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 55/100 | Training Loss: 0.112 | Valid Score: 0.825\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.826 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 0.111 | Valid Score: 0.827\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 0.110 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 58/100 | Training Loss: 0.110 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 0.110 | Valid Score: 0.827\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 60/100 | Training Loss: 0.109 | Valid Score: 0.825\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 61/100 | Training Loss: 0.109 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 62/100 | Training Loss: 0.109 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 63/100 | Training Loss: 0.108 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 0.109 | Valid Score: 0.830\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.830 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 65/100 | Training Loss: 0.108 | Valid Score: 0.826\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.830 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 66/100 | Training Loss: 0.108 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.830 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 67/100 | Training Loss: 0.108 | Valid Score: 0.828\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.830 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 68/100 | Training Loss: 0.108 | Valid Score: 0.827\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.830 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 69/100 | Training Loss: 0.107 | Valid Score: 0.828\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.830 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 70/100 | Training Loss: 0.107 | Valid Score: 0.825\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.830 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 0.107 | Valid Score: 0.834\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.834 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 72/100 | Training Loss: 0.107 | Valid Score: 0.828\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.834 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 73/100 | Training Loss: 0.106 | Valid Score: 0.830\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.834 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 74/100 | Training Loss: 0.106 | Valid Score: 0.828\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.834 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 75/100 | Training Loss: 0.106 | Valid Score: 0.831\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.834 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 76/100 | Training Loss: 0.107 | Valid Score: 0.831\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.834 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 77/100 | Training Loss: 0.107 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.834 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 78/100 | Training Loss: 0.106 | Valid Score: 0.829\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.834 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 79/100 | Training Loss: 0.106 | Valid Score: 0.827\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.834 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 80/100 | Training Loss: 0.105 | Valid Score: 0.831\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.834 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 81/100 | Training Loss: 0.105 | Valid Score: 0.830\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.834 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.834 \n",
            "\n",
            "Test Score: 0.780 \n",
            "\n",
            "Execution time: 847.703 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N2Bdvqee9p0m"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GraphSage 2 Layer"
      ],
      "metadata": {
        "id": "6-kJOQrW9qNu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GpLtwtOj9w0f"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size,aggregator_type='mean')\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.num_tasks,aggregator_type='mean')\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IILenjUD9w0f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "uRrUaBEm9w0g"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    #This tensor is used as a weight for positive examples in the binary cross-entropy loss.\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    #reduction='none': This specifies that the loss should not be reduced and returned element-wise.\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    #The mask tensor is used to mask out the loss for invalid labels.\n",
        "    loss = mask*criterion(output,label)\n",
        "    #The masked loss is summed and divided by the sum of the mask to compute the average loss.\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "_V-arGsb9w0g"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        # Zeros out the gradients of the model parameters using\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        # Computes the gradients of the loss with respect to the model parameters using\n",
        "        loss_train.backward()\n",
        "        # Updates the model parameters using\n",
        "        optimizer.step()\n",
        "        # Adds the loss for the current batch to\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DGGh9rO_9w0g"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "L_fHaINn9w0g"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "371ffdf5-2534-4274-d633-453096d554fe",
        "id": "KB8EOkwX9w0g"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.332 | Valid Score: 0.498\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.498 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.163 | Valid Score: 0.520\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.520 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.156 | Valid Score: 0.590\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.590 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.150 | Valid Score: 0.652\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.652 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.147 | Valid Score: 0.695\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.695 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.144 | Valid Score: 0.724\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.724 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.144 | Valid Score: 0.739\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.739 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.141 | Valid Score: 0.749\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.749 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 9/100 | Training Loss: 0.141 | Valid Score: 0.747\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.749 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.139 | Valid Score: 0.756\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.756 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.139 | Valid Score: 0.759\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.759 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.138 | Valid Score: 0.759\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.759 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.138 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 14/100 | Training Loss: 0.137 | Valid Score: 0.759\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.137 | Valid Score: 0.767\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.767 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 16/100 | Training Loss: 0.137 | Valid Score: 0.765\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.767 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 17/100 | Training Loss: 0.137 | Valid Score: 0.766\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.767 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 18/100 | Training Loss: 0.137 | Valid Score: 0.767\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.767 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.136 | Valid Score: 0.772\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.772 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 20/100 | Training Loss: 0.136 | Valid Score: 0.770\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.772 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 21/100 | Training Loss: 0.135 | Valid Score: 0.771\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.772 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.135 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.773 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 23/100 | Training Loss: 0.134 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.773 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.134 | Valid Score: 0.775\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.775 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 25/100 | Training Loss: 0.134 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.775 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 26/100 | Training Loss: 0.134 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.775 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.133 | Valid Score: 0.777\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.777 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 0.133 | Valid Score: 0.778\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 29/100 | Training Loss: 0.133 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 0.133 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.779 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 31/100 | Training Loss: 0.133 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.779 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 32/100 | Training Loss: 0.133 | Valid Score: 0.778\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.779 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.133 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.780 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 0.133 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.780 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.132 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 0.133 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.782 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 0.131 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 38/100 | Training Loss: 0.131 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.131 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 40/100 | Training Loss: 0.131 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 0.131 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 0.130 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.788 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 0.130 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 44/100 | Training Loss: 0.130 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 45/100 | Training Loss: 0.130 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 46/100 | Training Loss: 0.131 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 47/100 | Training Loss: 0.130 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.789 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 0.129 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 0.130 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 0.129 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 0.129 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 0.129 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.796 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 53/100 | Training Loss: 0.130 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.796 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 54/100 | Training Loss: 0.128 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.796 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 0.128 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.796 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 56/100 | Training Loss: 0.128 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.796 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 57/100 | Training Loss: 0.128 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.796 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 0.128 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 59/100 | Training Loss: 0.128 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 60/100 | Training Loss: 0.127 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 0.127 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 62/100 | Training Loss: 0.127 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 63/100 | Training Loss: 0.127 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 64/100 | Training Loss: 0.128 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 65/100 | Training Loss: 0.127 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 66/100 | Training Loss: 0.127 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 0.126 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 68/100 | Training Loss: 0.126 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 69/100 | Training Loss: 0.127 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 70/100 | Training Loss: 0.126 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 71/100 | Training Loss: 0.126 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 72/100 | Training Loss: 0.126 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 0.126 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 74/100 | Training Loss: 0.126 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 0.125 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 76/100 | Training Loss: 0.126 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 77/100 | Training Loss: 0.125 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 0.125 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 79/100 | Training Loss: 0.125 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 80/100 | Training Loss: 0.125 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 81/100 | Training Loss: 0.125 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 82/100 | Training Loss: 0.125 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 0.124 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 84/100 | Training Loss: 0.124 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 85/100 | Training Loss: 0.124 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 86/100 | Training Loss: 0.124 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 87/100 | Training Loss: 0.124 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 0.124 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 89/100 | Training Loss: 0.124 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 90/100 | Training Loss: 0.124 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 91/100 | Training Loss: 0.123 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 92/100 | Training Loss: 0.124 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 93/100 | Training Loss: 0.123 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 94/100 | Training Loss: 0.123 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 95/100 | Training Loss: 0.123 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 96/100 | Training Loss: 0.123 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 97/100 | Training Loss: 0.123 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 98/100 | Training Loss: 0.123 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.809 \n",
            "\n",
            "Test Score: 0.736 \n",
            "\n",
            "Execution time: 892.900 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kIlkoFlT9sUu"
      },
      "execution_count": 39,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}