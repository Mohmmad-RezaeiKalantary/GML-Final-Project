{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBABnTZKncKU",
        "outputId": "ca39291e-691c-4634-c11f-7cb662a4e863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl -f https://data.dgl.ai/wheels/repo.html\n",
        "\n",
        "!pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html"
      ],
      "metadata": {
        "id": "svYZdSBIDaAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3714e4f4-9a68-4026-d578-09a2a5b754e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Requirement already satisfied: dglgo in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.7.0)\n",
            "Requirement already satisfied: isort>=5.10.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (5.12.0)\n",
            "Requirement already satisfied: autopep8>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (2.0.2)\n",
            "Requirement already satisfied: numpydoc>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.5.0)\n",
            "Requirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.9)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.20 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.17.32)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0)\n",
            "Requirement already satisfied: ogb>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.3.6)\n",
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.10/dist-packages (from dglgo) (2022.9.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
            "Requirement already satisfied: pycodestyle>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.10.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinx>=4.2 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (7.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.65.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.26.16)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.6.3)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.7)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Requirement already satisfied: docutils<0.21,>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.20.1)\n",
            "Requirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spueVRy90Smx"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl.function as fn\n",
        "import torch.nn.functional as F\n",
        "import shutil\n",
        "from torch.utils.data import DataLoader\n",
        "import cloudpickle\n",
        "from dgl.nn import GraphConv\n",
        "from sklearn import preprocessing\n",
        "import math\n",
        "from dgl.nn import SAGEConv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUz_GYH70Smy"
      },
      "source": [
        "#### Set Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxEuIXHK0Smy"
      },
      "outputs": [],
      "source": [
        "current_dir = \"/content/drive/MyDrive/GML Final Project/\"\n",
        "checkpoint_path = current_dir + \"save_models/model_checkpoints/\" + \"checkpoint\"\n",
        "os.makedirs(checkpoint_path, exist_ok=True)\n",
        "\n",
        "best_model_path = current_dir + \"save_models/best_model/\"\n",
        "\n",
        "folder_data_temp = current_dir +\"data_temp/\"\n",
        "shutil.rmtree(folder_data_temp, ignore_errors=True)\n",
        "\n",
        "path_save = current_dir + \"Lipophilicity.zip\"\n",
        "shutil.unpack_archive(path_save, folder_data_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AGL3B0D0Smy"
      },
      "source": [
        "#### Custom PyTorch Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMxO0rAv0Smy"
      },
      "outputs": [],
      "source": [
        "\"\"\" Regression Dataset \"\"\"\n",
        "class DGLDatasetReg(torch.utils.data.Dataset):\n",
        "    def __init__(self, address, transform=None, train=False, scaler=None, scaler_regression=None):\n",
        "      #The train attribute is set to the value of the train argument, indicating if the dataset is for training or not.\n",
        "            self.train = train\n",
        "            self.scaler = scaler\n",
        "      #The data_set attribute is assigned the loaded graphs from the specified address using dgl.load_graphs.\n",
        "            self.data_set, train_labels_masks_globals = dgl.load_graphs(address+\".bin\")\n",
        "            num_graphs = len(self.data_set)\n",
        "      #The labels, masks, and globals are extracted from train_labels_masks_globals obtained from loading the graphs.\n",
        "      #They are reshaped into 2-dimensional tensors, where each row corresponds to the labels, masks, or globals of a graph.\n",
        "            self.labels = train_labels_masks_globals[\"labels\"].view(num_graphs,-1)\n",
        "            self.masks = train_labels_masks_globals[\"masks\"].view(num_graphs,-1)\n",
        "            self.globals = train_labels_masks_globals[\"globals\"].view(num_graphs,-1)\n",
        "      #The transform attribute is assigned the value of the transform argument, which can be used for data transformation if provided.\n",
        "            self.transform = transform\n",
        "      #The scaler_regression attribute is assigned the value of the scaler_regression argument, indicating whether a scaler should be used for regression labels or not.\n",
        "            self.scaler_regression = scaler_regression\n",
        "#The scaler_method method is defined to create and return a scaler object. If self.\n",
        "#train is True, it fits a StandardScaler to the labels and assigns it to the self.scaler attribute. The scaler is returned.\n",
        "    def scaler_method(self):\n",
        "        if self.train:\n",
        "            scaler = preprocessing.StandardScaler().fit(self.labels)\n",
        "            self.scaler = scaler\n",
        "        return self.scaler\n",
        "#The __len__ method returns the number of graphs in the dataset.\n",
        "    def __len__(self):\n",
        "        return len(self.data_set)\n",
        "#The __getitem__ method retrieves an item from the dataset at the given index (idx). There are two different paths based on whether self.scaler_regression is True or not:\n",
        "    def __getitem__(self, idx):\n",
        "        if self.scaler_regression:\n",
        "            \"\"\" With Scaler\"\"\"\n",
        "            return  self.data_set[idx], torch.tensor(self.scaler.transform(self.labels)[idx]).float(), self.masks[idx], self.globals[idx]\n",
        "        else:\n",
        "            \"\"\" Without Scaler \"\"\"\n",
        "            return  self.data_set[idx], self.labels[idx].float(), self.masks[idx], self.globals[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwPHz3jO0Smz"
      },
      "source": [
        "#### Defining Train, Validation, and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPMBUvb80Smz",
        "outputId": "63c53976-6747-472d-83c0-397f6754f73c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3360 420 420\n"
          ]
        }
      ],
      "source": [
        "scaler = {}\n",
        "path_data_temp = folder_data_temp + \"scaffold\"+\"_\"+str(0)\n",
        "train_set = DGLDatasetReg(address=path_data_temp+\"_train\", train=True)\n",
        "scaler = train_set.scaler_method()\n",
        "val_set = DGLDatasetReg(address=path_data_temp+\"_val\", scaler=scaler)\n",
        "test_set = DGLDatasetReg(address=path_data_temp+\"_test\", scaler=scaler)\n",
        "\n",
        "print(len(train_set), len(val_set), len(test_set))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0acizkE0Sm0"
      },
      "source": [
        "#### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gO6nHb_q0Sm0"
      },
      "outputs": [],
      "source": [
        "def collate(batch):\n",
        "    # batch is a list of tuples (graphs, labels, masks, globals)\n",
        "    # Concatenate a sequence of graphs\n",
        "\n",
        "    ### This line extracts the graphs from each tuple in the batch and creates a list of individual graphs.\n",
        "    graphs = [e[0] for e in batch]\n",
        "    ### This line uses the dgl.batch() function to combine the individual graphs into a single graph batch g\n",
        "    g = dgl.batch(graphs)\n",
        "\n",
        "    # Concatenate a sequence of tensors (labels) along a new dimension\n",
        "\n",
        "    ### This line extracts the labels from each tuple in the batch and creates a list of individual label tensors.\n",
        "    labels = [e[1] for e in batch]\n",
        "    ### This line uses torch.stack() to concatenate the individual label tensors along a new dimension (dimension 0) and create a single tensor labels representing the labels for the entire batch.\n",
        "    labels = torch.stack(labels, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (masks) along a new dimension\n",
        "\n",
        "    ### This line extracts the masks from each tuple in the batch and creates a list of individual mask tensors.\n",
        "    masks = [e[2] for e in batch]\n",
        "    ### This line uses torch.stack() to concatenate the individual mask tensors along a new dimension (dimension 0) and create a single tensor masks representing the masks for the entire batch.\n",
        "    masks = torch.stack(masks, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (globals) along a new dimension\n",
        "\n",
        "    ### This line extracts the global features from each tuple in the batch and creates a list of individual global feature tensors.\n",
        "    globals = [e[3] for e in batch]\n",
        "    ### This line uses torch.stack() to concatenate the individual global feature tensors along a new dimension (dimension 0) and create a single tensor globals representing the global features for the entire batch.\n",
        "    globals = torch.stack(globals, 0)\n",
        "\n",
        "    return g, labels, masks, globals\n",
        "\n",
        "\n",
        "def loader(batch_size=64):\n",
        "    train_dataloader = DataLoader(train_set,\n",
        "                              batch_size=batch_size,\n",
        "                              collate_fn=collate,\n",
        "                              drop_last=False,\n",
        "                              shuffle=True,\n",
        "                              num_workers=1)\n",
        "\n",
        "    val_dataloader =  DataLoader(val_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7oLkbLh0Sm1"
      },
      "outputs": [],
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = loader(batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3VavJsl0Sm1"
      },
      "source": [
        "#### Defining A GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lk7pfCu0Sm1"
      },
      "source": [
        "##### Some Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcuTUQry0Sm2"
      },
      "outputs": [],
      "source": [
        "#Bace dataset has 1 task. Some other datasets may have some more number of tasks, e.g., tox21 has 12 tasks.\n",
        "num_tasks = 1\n",
        "\n",
        "# Size of global feature of each graph\n",
        "global_size = 200\n",
        "\n",
        "# Number of epochs to train the model\n",
        "num_epochs = 100\n",
        "\n",
        "# Number of steps to wait if the model performance on the validation set does not improve\n",
        "patience = 10\n",
        "\n",
        "#Configurations to instantiate the model\n",
        "config = {\"node_feature_size\":127, \"edge_feature_size\":12, \"hidden_size\":100}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN 3 Layer"
      ],
      "metadata": {
        "id": "0uYAZEt_AfYX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDPHO0FM0Sm2"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv3 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks=1):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "       prediction = model(mol_dgl_graph, globals)\n",
        "       prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "       labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "       loss = loss_sum(prediction, labels)\n",
        "       final_loss += loss.item()\n",
        "\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "\n",
        "  return final_loss / num_tasks"
      ],
      "metadata": {
        "id": "iEPWwpA0ugl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OTPYKMnqMSu"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCSUYYtQqMSv"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjt9YFLSqMSv"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 100000\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader,scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMSYT7lAqMSv"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237652db-e0cd-4952-9969-6ab414a2d486",
        "id": "WprNKX-fqMSv"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 5.074 | Valid Score: 2.333\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 2.333 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 3.110 | Valid Score: 1.766\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 1.766 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 1.986 | Valid Score: 1.537\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 1.537 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 1.793 | Valid Score: 1.516\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 1.516 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 1.752 | Valid Score: 1.500\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 1.500 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 1.711 | Valid Score: 1.484\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 1.484 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 1.676 | Valid Score: 1.471\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 1.471 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 1.640 | Valid Score: 1.458\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 1.458 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 1.613 | Valid Score: 1.447\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 1.447 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 1.579 | Valid Score: 1.437\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 1.437 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 1.555 | Valid Score: 1.427\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 1.427 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 1.531 | Valid Score: 1.417\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 1.417 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 1.510 | Valid Score: 1.407\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 1.407 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 1.486 | Valid Score: 1.399\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 1.399 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 1.468 | Valid Score: 1.391\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 1.391 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 1.453 | Valid Score: 1.385\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 1.385 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 1.430 | Valid Score: 1.381\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 1.381 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 1.425 | Valid Score: 1.373\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 1.373 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 1.404 | Valid Score: 1.369\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 1.369 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 1.389 | Valid Score: 1.363\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 1.363 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 1.378 | Valid Score: 1.363\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 1.363 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 1.369 | Valid Score: 1.356\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 1.356 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 1.358 | Valid Score: 1.356\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 1.356 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 1.357 | Valid Score: 1.352\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 1.352 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 1.343 | Valid Score: 1.344\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 1.344 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 1.333 | Valid Score: 1.341\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 1.341 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 1.316 | Valid Score: 1.340\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 1.340 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 1.318 | Valid Score: 1.337\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 1.337 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 1.313 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 1.302 | Valid Score: 1.331\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 1.331 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 1.300 | Valid Score: 1.328\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 1.328 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 1.281 | Valid Score: 1.326\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 1.326 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 1.281 | Valid Score: 1.324\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 1.324 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 1.273 | Valid Score: 1.322\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 1.322 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 1.264 | Valid Score: 1.321\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 1.321 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 1.261 | Valid Score: 1.320\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 1.320 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 1.249 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 1.317 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 38/100 | Training Loss: 1.251 | Valid Score: 1.318\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 1.317 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 1.244 | Valid Score: 1.316\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 1.316 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 40/100 | Training Loss: 1.245 | Valid Score: 1.316\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 1.316 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 41/100 | Training Loss: 1.238 | Valid Score: 1.320\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.316 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 1.226 | Valid Score: 1.314\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.314 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 43/100 | Training Loss: 1.228 | Valid Score: 1.320\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.314 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 44/100 | Training Loss: 1.224 | Valid Score: 1.314\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.314 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 1.217 | Valid Score: 1.312\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.312 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 1.216 | Valid Score: 1.311\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 1.214 | Valid Score: 1.311\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 48/100 | Training Loss: 1.211 | Valid Score: 1.311\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 49/100 | Training Loss: 1.202 | Valid Score: 1.311\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 50/100 | Training Loss: 1.199 | Valid Score: 1.311\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 1.205 | Valid Score: 1.309\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.309 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 52/100 | Training Loss: 1.194 | Valid Score: 1.310\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.309 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 53/100 | Training Loss: 1.194 | Valid Score: 1.312\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.309 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 1.193 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 1.188 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 56/100 | Training Loss: 1.186 | Valid Score: 1.312\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 57/100 | Training Loss: 1.181 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 1.180 | Valid Score: 1.307\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.307 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 59/100 | Training Loss: 1.180 | Valid Score: 1.312\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.307 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 60/100 | Training Loss: 1.180 | Valid Score: 1.310\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.307 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 1.173 | Valid Score: 1.306\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.306 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 1.177 | Valid Score: 1.305\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.305 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 1.170 | Valid Score: 1.305\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.305 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 64/100 | Training Loss: 1.170 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.305 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 1.172 | Valid Score: 1.304\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 66/100 | Training Loss: 1.167 | Valid Score: 1.306\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 67/100 | Training Loss: 1.166 | Valid Score: 1.304\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 1.163 | Valid Score: 1.303\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.303 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 69/100 | Training Loss: 1.159 | Valid Score: 1.312\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.303 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 70/100 | Training Loss: 1.169 | Valid Score: 1.312\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.303 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 71/100 | Training Loss: 1.163 | Valid Score: 1.304\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.303 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 1.159 | Valid Score: 1.301\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.301 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 73/100 | Training Loss: 1.154 | Valid Score: 1.306\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.301 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 74/100 | Training Loss: 1.154 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.300 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 1.151 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.300 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 76/100 | Training Loss: 1.146 | Valid Score: 1.301\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.300 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 77/100 | Training Loss: 1.149 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.300 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 78/100 | Training Loss: 1.145 | Valid Score: 1.303\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.300 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 1.147 | Valid Score: 1.299\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.299 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 80/100 | Training Loss: 1.146 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.299 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 1.142 | Valid Score: 1.298\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.298 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 82/100 | Training Loss: 1.146 | Valid Score: 1.298\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.298 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 83/100 | Training Loss: 1.137 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.298 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 84/100 | Training Loss: 1.140 | Valid Score: 1.298\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.298 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 85/100 | Training Loss: 1.132 | Valid Score: 1.299\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.298 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 86/100 | Training Loss: 1.133 | Valid Score: 1.298\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.298 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 1.132 | Valid Score: 1.296\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.296 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 88/100 | Training Loss: 1.133 | Valid Score: 1.298\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.296 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 89/100 | Training Loss: 1.136 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.296 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 90/100 | Training Loss: 1.131 | Valid Score: 1.306\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.296 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 91/100 | Training Loss: 1.129 | Valid Score: 1.296\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.296 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 1.131 | Valid Score: 1.295\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.295 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 93/100 | Training Loss: 1.135 | Valid Score: 1.298\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.295 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 94/100 | Training Loss: 1.123 | Valid Score: 1.294\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.294 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 95/100 | Training Loss: 1.128 | Valid Score: 1.294\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.294 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 96/100 | Training Loss: 1.129 | Valid Score: 1.297\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.294 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 97/100 | Training Loss: 1.124 | Valid Score: 1.296\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.294 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 98/100 | Training Loss: 1.126 | Valid Score: 1.293\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.293 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 99/100 | Training Loss: 1.123 | Valid Score: 1.302\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.293 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 100/100 | Training Loss: 1.126 | Valid Score: 1.304\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.293 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.293 \n",
            "\n",
            "Test Score: 1.370 \n",
            "\n",
            "Execution time: 138.190 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN 2 Layer"
      ],
      "metadata": {
        "id": "mInZ4h7VGEAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "D96kc9b1GG-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks=1):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "       prediction = model(mol_dgl_graph, globals)\n",
        "       prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "       labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "       loss = loss_sum(prediction, labels)\n",
        "       final_loss += loss.item()\n",
        "\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "\n",
        "  return final_loss / num_tasks"
      ],
      "metadata": {
        "id": "g6gw-4-oGLoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt-VXcG1GLoo"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHp_w94NGLoo"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzC2XMTvGLop"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 100000\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader,scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pby56tsGGLop"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f02455-e034-4732-e0c4-913e8c8a43cf",
        "id": "TW-WXwetGLop"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 5.019 | Valid Score: 2.441\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 2.441 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 3.897 | Valid Score: 2.130\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 2.130 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 2.990 | Valid Score: 1.857\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 1.857 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 2.337 | Valid Score: 1.654\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 1.654 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 1.958 | Valid Score: 1.554\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 1.554 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 1.802 | Valid Score: 1.524\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 1.524 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 1.769 | Valid Score: 1.515\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 1.515 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 1.748 | Valid Score: 1.510\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 1.510 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 1.737 | Valid Score: 1.505\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 1.505 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 1.731 | Valid Score: 1.500\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 1.500 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 1.712 | Valid Score: 1.494\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 1.494 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 1.698 | Valid Score: 1.489\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 1.489 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 1.686 | Valid Score: 1.484\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 1.484 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 1.674 | Valid Score: 1.479\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 1.479 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 1.661 | Valid Score: 1.474\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 1.474 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 1.650 | Valid Score: 1.469\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 1.469 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 1.644 | Valid Score: 1.464\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 1.464 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 1.629 | Valid Score: 1.459\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 1.459 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 1.620 | Valid Score: 1.455\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 1.455 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 1.605 | Valid Score: 1.450\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 1.450 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 1.595 | Valid Score: 1.446\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 1.446 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 1.583 | Valid Score: 1.442\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 1.442 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 1.577 | Valid Score: 1.438\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 1.438 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 1.566 | Valid Score: 1.433\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 1.433 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 1.557 | Valid Score: 1.430\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 1.430 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 1.549 | Valid Score: 1.426\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 1.426 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 1.547 | Valid Score: 1.422\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 1.422 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 1.539 | Valid Score: 1.419\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 1.419 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 1.518 | Valid Score: 1.415\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 1.415 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 1.517 | Valid Score: 1.413\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 1.413 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 1.507 | Valid Score: 1.409\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 1.409 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 1.500 | Valid Score: 1.406\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 1.406 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 1.489 | Valid Score: 1.403\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 1.403 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 1.484 | Valid Score: 1.401\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 1.401 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 1.477 | Valid Score: 1.398\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 1.398 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 1.478 | Valid Score: 1.396\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 1.396 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 1.461 | Valid Score: 1.394\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 1.394 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 1.460 | Valid Score: 1.392\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 1.392 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 1.451 | Valid Score: 1.389\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 1.389 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 1.445 | Valid Score: 1.387\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 1.387 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 1.443 | Valid Score: 1.384\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.384 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 1.437 | Valid Score: 1.383\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.383 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 1.434 | Valid Score: 1.382\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.382 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 1.429 | Valid Score: 1.379\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.379 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 1.422 | Valid Score: 1.377\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.377 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 1.420 | Valid Score: 1.376\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.376 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 1.417 | Valid Score: 1.374\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.374 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 1.412 | Valid Score: 1.372\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.372 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 1.407 | Valid Score: 1.370\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.370 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 1.398 | Valid Score: 1.368\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.368 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 1.395 | Valid Score: 1.366\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.366 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 1.394 | Valid Score: 1.365\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.365 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 1.392 | Valid Score: 1.363\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.363 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 1.384 | Valid Score: 1.361\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.361 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 1.384 | Valid Score: 1.360\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.360 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 1.374 | Valid Score: 1.359\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.359 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 57/100 | Training Loss: 1.371 | Valid Score: 1.357\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.357 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 1.364 | Valid Score: 1.356\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.356 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 1.370 | Valid Score: 1.354\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.354 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 1.360 | Valid Score: 1.353\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.353 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 1.355 | Valid Score: 1.353\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.353 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 1.350 | Valid Score: 1.351\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.351 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 1.345 | Valid Score: 1.350\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.350 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 1.345 | Valid Score: 1.349\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.349 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 1.343 | Valid Score: 1.348\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.348 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 66/100 | Training Loss: 1.336 | Valid Score: 1.348\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.348 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 67/100 | Training Loss: 1.339 | Valid Score: 1.348\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.348 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 1.333 | Valid Score: 1.346\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.346 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 1.332 | Valid Score: 1.345\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.345 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 1.325 | Valid Score: 1.344\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.344 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 1.317 | Valid Score: 1.344\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.344 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 1.319 | Valid Score: 1.343\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.343 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 1.312 | Valid Score: 1.342\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.342 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 74/100 | Training Loss: 1.313 | Valid Score: 1.342\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.342 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 1.314 | Valid Score: 1.341\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.341 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 76/100 | Training Loss: 1.310 | Valid Score: 1.341\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.341 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 1.310 | Valid Score: 1.340\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.340 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 1.308 | Valid Score: 1.340\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.340 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 1.299 | Valid Score: 1.339\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.339 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 80/100 | Training Loss: 1.302 | Valid Score: 1.338\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.338 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 1.297 | Valid Score: 1.337\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.337 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 82/100 | Training Loss: 1.297 | Valid Score: 1.337\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.337 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 1.300 | Valid Score: 1.336\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.336 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 84/100 | Training Loss: 1.289 | Valid Score: 1.336\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.336 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 85/100 | Training Loss: 1.294 | Valid Score: 1.336\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.336 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 86/100 | Training Loss: 1.287 | Valid Score: 1.335\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.335 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 1.281 | Valid Score: 1.335\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.335 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 1.291 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.334 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 1.282 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.334 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 90/100 | Training Loss: 1.276 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.334 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 91/100 | Training Loss: 1.275 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.334 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 1.273 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.334 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 93/100 | Training Loss: 1.275 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 94/100 | Training Loss: 1.272 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 95/100 | Training Loss: 1.270 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 96/100 | Training Loss: 1.267 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 97/100 | Training Loss: 1.272 | Valid Score: 1.332\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 98/100 | Training Loss: 1.267 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 99/100 | Training Loss: 1.262 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 100/100 | Training Loss: 1.261 | Valid Score: 1.332\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.332 \n",
            "\n",
            "Test Score: 1.447 \n",
            "\n",
            "Execution time: 128.097 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GraphSAGE 2 Layer"
      ],
      "metadata": {
        "id": "2tLj_lcUGHQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "8NEqbKEvG205"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks=1):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "       prediction = model(mol_dgl_graph, globals)\n",
        "       prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "       labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "       loss = loss_sum(prediction, labels)\n",
        "       final_loss += loss.item()\n",
        "\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "\n",
        "  return final_loss / num_tasks"
      ],
      "metadata": {
        "id": "J0uyl5_iHDEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwA8cCKyHDEi"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B2vVS4_HDEi"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcqinIWFHDEi"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 100000\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader,scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YewrYxgCHDEi"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b39e42-a3bd-439f-a622-114ee953f676",
        "id": "4nmxP5CvHDEi"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 5.209 | Valid Score: 2.489\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 2.489 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 4.040 | Valid Score: 2.173\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 2.173 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 3.065 | Valid Score: 1.881\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 1.881 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 2.338 | Valid Score: 1.660\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 1.660 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 1.929 | Valid Score: 1.553\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 1.553 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 1.773 | Valid Score: 1.523\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 1.523 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 1.744 | Valid Score: 1.515\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 1.515 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 1.722 | Valid Score: 1.508\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 1.508 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 1.708 | Valid Score: 1.501\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 1.501 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 1.694 | Valid Score: 1.495\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 1.495 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 1.670 | Valid Score: 1.488\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 1.488 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 1.663 | Valid Score: 1.482\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 1.482 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 1.647 | Valid Score: 1.476\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 1.476 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 1.632 | Valid Score: 1.471\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 1.471 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 1.616 | Valid Score: 1.465\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 1.465 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 1.604 | Valid Score: 1.459\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 1.459 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 1.592 | Valid Score: 1.455\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 1.455 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 1.582 | Valid Score: 1.450\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 1.450 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 1.576 | Valid Score: 1.445\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 1.445 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 1.557 | Valid Score: 1.440\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 1.440 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 1.554 | Valid Score: 1.435\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 1.435 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 1.541 | Valid Score: 1.431\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 1.431 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 1.530 | Valid Score: 1.427\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 1.427 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 1.528 | Valid Score: 1.423\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 1.423 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 1.507 | Valid Score: 1.420\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 1.420 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 1.502 | Valid Score: 1.416\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 1.416 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 1.496 | Valid Score: 1.413\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 1.413 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 1.486 | Valid Score: 1.409\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 1.409 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 1.486 | Valid Score: 1.406\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 1.406 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 1.472 | Valid Score: 1.403\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 1.403 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 1.464 | Valid Score: 1.400\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 1.400 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 1.458 | Valid Score: 1.397\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 1.397 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 1.452 | Valid Score: 1.395\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 1.395 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 1.450 | Valid Score: 1.392\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 1.392 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 1.442 | Valid Score: 1.389\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 1.389 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 1.437 | Valid Score: 1.387\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 1.387 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 1.432 | Valid Score: 1.384\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 1.384 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 1.424 | Valid Score: 1.382\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 1.382 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 1.424 | Valid Score: 1.380\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 1.380 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 1.418 | Valid Score: 1.378\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 1.378 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 1.412 | Valid Score: 1.376\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.376 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 1.408 | Valid Score: 1.374\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.374 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 1.402 | Valid Score: 1.372\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.372 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 1.395 | Valid Score: 1.370\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.370 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 1.398 | Valid Score: 1.369\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.369 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 1.387 | Valid Score: 1.366\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.366 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 1.379 | Valid Score: 1.366\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.366 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 1.381 | Valid Score: 1.363\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.363 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 1.374 | Valid Score: 1.361\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.361 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 1.377 | Valid Score: 1.359\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.359 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 1.370 | Valid Score: 1.359\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.359 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 1.361 | Valid Score: 1.357\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.357 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 1.358 | Valid Score: 1.355\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.355 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 1.356 | Valid Score: 1.354\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.354 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 1.355 | Valid Score: 1.353\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.353 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 1.355 | Valid Score: 1.352\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.352 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 57/100 | Training Loss: 1.347 | Valid Score: 1.351\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.351 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 58/100 | Training Loss: 1.338 | Valid Score: 1.352\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.351 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 1.342 | Valid Score: 1.349\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.349 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 1.338 | Valid Score: 1.348\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.348 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 1.339 | Valid Score: 1.347\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.347 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 1.334 | Valid Score: 1.345\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.345 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 1.331 | Valid Score: 1.344\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.344 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 1.323 | Valid Score: 1.343\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.343 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 1.323 | Valid Score: 1.342\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.342 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 66/100 | Training Loss: 1.315 | Valid Score: 1.343\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.342 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 1.315 | Valid Score: 1.342\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.342 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 1.309 | Valid Score: 1.341\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.341 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 1.312 | Valid Score: 1.340\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.340 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 1.312 | Valid Score: 1.339\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.339 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 1.311 | Valid Score: 1.338\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.338 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 1.303 | Valid Score: 1.338\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.338 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 1.298 | Valid Score: 1.337\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.337 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 74/100 | Training Loss: 1.297 | Valid Score: 1.336\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.336 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 1.303 | Valid Score: 1.336\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.336 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 76/100 | Training Loss: 1.295 | Valid Score: 1.336\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.336 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 1.293 | Valid Score: 1.335\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.335 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 78/100 | Training Loss: 1.287 | Valid Score: 1.336\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.335 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 1.292 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.334 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 80/100 | Training Loss: 1.283 | Valid Score: 1.336\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.334 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 1.281 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.334 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 82/100 | Training Loss: 1.280 | Valid Score: 1.335\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.334 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 1.278 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 84/100 | Training Loss: 1.279 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 85/100 | Training Loss: 1.273 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 86/100 | Training Loss: 1.271 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 1.275 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 88/100 | Training Loss: 1.276 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 1.269 | Valid Score: 1.332\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 90/100 | Training Loss: 1.272 | Valid Score: 1.332\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 91/100 | Training Loss: 1.266 | Valid Score: 1.332\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 92/100 | Training Loss: 1.268 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 93/100 | Training Loss: 1.263 | Valid Score: 1.332\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 94/100 | Training Loss: 1.263 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 95/100 | Training Loss: 1.258 | Valid Score: 1.332\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 96/100 | Training Loss: 1.259 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 97/100 | Training Loss: 1.255 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 98/100 | Training Loss: 1.255 | Valid Score: 1.331\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.331 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 99/100 | Training Loss: 1.254 | Valid Score: 1.332\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.331 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 100/100 | Training Loss: 1.256 | Valid Score: 1.332\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.331 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.331 \n",
            "\n",
            "Test Score: 1.440 \n",
            "\n",
            "Execution time: 116.118 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GraphSAGE 3 Layer"
      ],
      "metadata": {
        "id": "bOu1vsLkG3Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size,aggregator_type='mean')\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.hidden_size,aggregator_type='mean')\n",
        "        self.conv3 = SAGEConv(self.hidden_size, self.num_tasks,aggregator_type='mean')\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ],
      "metadata": {
        "id": "NWFh_9dT1Eos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks=1):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "       prediction = model(mol_dgl_graph, globals)\n",
        "       prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "       labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "       loss = loss_sum(prediction, labels)\n",
        "       final_loss += loss.item()\n",
        "\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "\n",
        "  return final_loss / num_tasks"
      ],
      "metadata": {
        "id": "gJe2woCfH4Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyuF-2BiH4Jp"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pai-jJyH4Jp"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_5Qt4m8H4Jq"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 100000\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader,scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5zCMmqMH4Jq"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "079f0d4a-166b-4c4d-e55c-41a2d4eb7f90",
        "id": "LP0svnJUH4Jq"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 2.334 | Valid Score: 1.572\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 1.572 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 1.744 | Valid Score: 1.488\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 1.488 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 1.575 | Valid Score: 1.446\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 1.446 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 1.489 | Valid Score: 1.416\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 1.416 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 1.430 | Valid Score: 1.402\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 1.402 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 1.383 | Valid Score: 1.379\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 1.379 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 1.346 | Valid Score: 1.364\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 1.364 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 1.300 | Valid Score: 1.357\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 1.357 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 1.278 | Valid Score: 1.341\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 1.341 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 1.249 | Valid Score: 1.337\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 1.337 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 1.233 | Valid Score: 1.336\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 1.336 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 1.212 | Valid Score: 1.319\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 1.319 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 1.187 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 1.317 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 1.169 | Valid Score: 1.312\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 1.312 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 15/100 | Training Loss: 1.155 | Valid Score: 1.321\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 1.312 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 16/100 | Training Loss: 1.163 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 1.312 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 1.133 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 1.300 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 1.122 | Valid Score: 1.295\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 1.295 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 1.109 | Valid Score: 1.293\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 1.293 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 20/100 | Training Loss: 1.103 | Valid Score: 1.295\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 1.293 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 1.100 | Valid Score: 1.290\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 1.290 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 1.089 | Valid Score: 1.285\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 1.285 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 23/100 | Training Loss: 1.079 | Valid Score: 1.285\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 1.285 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 1.070 | Valid Score: 1.282\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 1.282 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 1.059 | Valid Score: 1.281\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 1.281 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 26/100 | Training Loss: 1.048 | Valid Score: 1.287\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 1.281 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 1.043 | Valid Score: 1.280\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 1.280 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 1.041 | Valid Score: 1.281\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 1.280 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 1.037 | Valid Score: 1.280\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 1.280 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 30/100 | Training Loss: 1.024 | Valid Score: 1.292\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 1.280 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 1.039 | Valid Score: 1.275\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 1.275 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 32/100 | Training Loss: 1.013 | Valid Score: 1.279\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 1.275 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 1.003 | Valid Score: 1.274\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 1.274 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 1.006 | Valid Score: 1.273\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 1.273 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 35/100 | Training Loss: 1.000 | Valid Score: 1.289\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 1.273 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 36/100 | Training Loss: 0.989 | Valid Score: 1.279\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 1.273 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 37/100 | Training Loss: 0.984 | Valid Score: 1.274\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 1.273 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 0.982 | Valid Score: 1.272\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 1.272 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 39/100 | Training Loss: 0.975 | Valid Score: 1.272\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 1.272 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 0.964 | Valid Score: 1.268\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 1.268 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 41/100 | Training Loss: 0.962 | Valid Score: 1.274\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.268 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 0.961 | Valid Score: 1.267\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.267 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 43/100 | Training Loss: 0.958 | Valid Score: 1.268\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.267 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 0.949 | Valid Score: 1.267\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.267 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 45/100 | Training Loss: 0.953 | Valid Score: 1.269\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.267 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 46/100 | Training Loss: 0.945 | Valid Score: 1.269\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.267 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 47/100 | Training Loss: 0.940 | Valid Score: 1.275\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.267 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 48/100 | Training Loss: 0.952 | Valid Score: 1.270\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.267 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 0.932 | Valid Score: 1.262\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.262 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 50/100 | Training Loss: 0.932 | Valid Score: 1.265\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.262 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 51/100 | Training Loss: 0.922 | Valid Score: 1.269\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.262 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 52/100 | Training Loss: 0.929 | Valid Score: 1.264\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.262 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 0.919 | Valid Score: 1.261\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.261 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 54/100 | Training Loss: 0.914 | Valid Score: 1.265\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.261 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 55/100 | Training Loss: 0.914 | Valid Score: 1.261\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.261 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 0.910 | Valid Score: 1.261\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.261 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 57/100 | Training Loss: 0.907 | Valid Score: 1.260\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.260 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 58/100 | Training Loss: 0.895 | Valid Score: 1.261\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.260 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 59/100 | Training Loss: 0.887 | Valid Score: 1.273\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.260 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 60/100 | Training Loss: 0.902 | Valid Score: 1.262\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.260 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 0.888 | Valid Score: 1.258\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.258 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 62/100 | Training Loss: 0.877 | Valid Score: 1.259\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.258 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 63/100 | Training Loss: 0.886 | Valid Score: 1.269\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.258 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 0.877 | Valid Score: 1.258\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.258 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 0.873 | Valid Score: 1.257\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.257 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 66/100 | Training Loss: 0.879 | Valid Score: 1.257\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.257 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 67/100 | Training Loss: 0.874 | Valid Score: 1.261\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.257 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 68/100 | Training Loss: 0.875 | Valid Score: 1.258\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.257 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 0.867 | Valid Score: 1.256\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.256 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 70/100 | Training Loss: 0.870 | Valid Score: 1.272\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.256 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 71/100 | Training Loss: 0.865 | Valid Score: 1.256\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.256 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 72/100 | Training Loss: 0.861 | Valid Score: 1.260\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.256 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 73/100 | Training Loss: 0.851 | Valid Score: 1.264\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.256 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 74/100 | Training Loss: 0.845 | Valid Score: 1.254\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.254 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 0.846 | Valid Score: 1.252\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.252 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 76/100 | Training Loss: 0.850 | Valid Score: 1.271\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.252 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 0.849 | Valid Score: 1.251\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.251 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 78/100 | Training Loss: 0.832 | Valid Score: 1.253\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.251 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 79/100 | Training Loss: 0.834 | Valid Score: 1.256\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.251 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 80/100 | Training Loss: 0.827 | Valid Score: 1.249\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.249 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 81/100 | Training Loss: 0.830 | Valid Score: 1.253\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.249 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 82/100 | Training Loss: 0.824 | Valid Score: 1.247\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.247 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 83/100 | Training Loss: 0.822 | Valid Score: 1.249\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.247 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 84/100 | Training Loss: 0.824 | Valid Score: 1.249\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.247 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 85/100 | Training Loss: 0.827 | Valid Score: 1.248\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.247 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 86/100 | Training Loss: 0.816 | Valid Score: 1.261\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.247 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 87/100 | Training Loss: 0.826 | Valid Score: 1.262\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.247 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 88/100 | Training Loss: 0.822 | Valid Score: 1.253\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.247 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 89/100 | Training Loss: 0.819 | Valid Score: 1.266\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.247 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 90/100 | Training Loss: 0.816 | Valid Score: 1.245\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.245 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 91/100 | Training Loss: 0.813 | Valid Score: 1.244\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.244 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 92/100 | Training Loss: 0.805 | Valid Score: 1.246\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.244 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 93/100 | Training Loss: 0.803 | Valid Score: 1.258\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.244 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 94/100 | Training Loss: 0.806 | Valid Score: 1.267\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.244 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 95/100 | Training Loss: 0.812 | Valid Score: 1.248\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.244 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 96/100 | Training Loss: 0.803 | Valid Score: 1.253\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.244 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 97/100 | Training Loss: 0.796 | Valid Score: 1.243\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.243 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 98/100 | Training Loss: 0.791 | Valid Score: 1.247\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.243 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 99/100 | Training Loss: 0.802 | Valid Score: 1.247\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.243 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 100/100 | Training Loss: 0.790 | Valid Score: 1.248\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.243 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.243 \n",
            "\n",
            "Test Score: 1.294 \n",
            "\n",
            "Execution time: 132.616 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    }
  ]
}